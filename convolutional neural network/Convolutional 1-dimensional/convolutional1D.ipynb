{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional1D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhBzvM7V_z4l"
      },
      "source": [
        "import os \n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import time \n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Flatten\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF1rhED0A5Ke",
        "outputId": "11c6a967-f47d-47ed-fd02-c07c2ec34671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vNGEnGwA8WU",
        "outputId": "a888ff06-a7b6-4d82-a722-c23f258a679c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGRcW7UABQTK"
      },
      "source": [
        "# define some parameters \n",
        "\n",
        "vocab_size = 10000\n",
        "max_sequence_length = 1000\n",
        "embedding_dim = 200 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwfcO131XAr3"
      },
      "source": [
        "# Tokenizer and Sequences \n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, lower=False)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_matrix(X_train)\n",
        "X_test = tokenizer.texts_to_matrix(X_test)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
        "X_test = pad_sequences(X_test, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJlZjDVzXTTa",
        "outputId": "2b0aee52-7b30-451b-bf47-ecc23a2aa32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# word index \n",
        "word_index = tokenizer.word_index\n",
        "print(\"Vocabulary size: \", len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size:  9998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZOtmQ6GbL1P"
      },
      "source": [
        "<br>\n",
        "<hr>\n",
        "\n",
        "### Conv1D \n",
        "\n",
        "The input of Conv1D has the following format: format = (sequences of vector, number of dimensions)\n",
        "\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0XYGddGYwYC",
        "outputId": "3b224364-67ba-4597-a5a2-4942e9f37c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Convolutional 1D for text \n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size,\n",
        "                    output_dim=embedding_dim,\n",
        "                    input_length=max_sequence_length))\n",
        "model.add(Conv1D(filters=16, kernel_size=1, strides=1, padding=\"valid\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=1, padding=\"valid\"))\n",
        "model.add(Conv1D(filters=32, kernel_size=1, strides=1, padding=\"valid\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=1, padding=\"valid\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1000, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 1000, 16)          3216      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 999, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 999, 32)           544       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 998, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 31936)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               16351744  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 18,356,017\n",
            "Trainable params: 18,356,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ1Cs2h_Z2Vz",
        "outputId": "a99ae5af-c48a-4a58-9ca5-20f50172bb1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 28s 144ms/step - loss: 0.5196 - accuracy: 0.7289 - val_loss: 0.4175 - val_accuracy: 0.8124\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 32s 165ms/step - loss: 0.4001 - accuracy: 0.8184 - val_loss: 0.3893 - val_accuracy: 0.8217\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 33s 168ms/step - loss: 0.3746 - accuracy: 0.8296 - val_loss: 0.3735 - val_accuracy: 0.8326\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 33s 166ms/step - loss: 0.3575 - accuracy: 0.8402 - val_loss: 0.3737 - val_accuracy: 0.8312\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 31s 160ms/step - loss: 0.3388 - accuracy: 0.8514 - val_loss: 0.3780 - val_accuracy: 0.8293\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 32s 163ms/step - loss: 0.3219 - accuracy: 0.8605 - val_loss: 0.3771 - val_accuracy: 0.8343\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 33s 167ms/step - loss: 0.2972 - accuracy: 0.8733 - val_loss: 0.3839 - val_accuracy: 0.8262\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 32s 164ms/step - loss: 0.2752 - accuracy: 0.8846 - val_loss: 0.3984 - val_accuracy: 0.8309\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 31s 160ms/step - loss: 0.2459 - accuracy: 0.8986 - val_loss: 0.4353 - val_accuracy: 0.8208\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 31s 158ms/step - loss: 0.2128 - accuracy: 0.9138 - val_loss: 0.4610 - val_accuracy: 0.8204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d93a19e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPJVs1XriZTN"
      },
      "source": [
        "<hr>\n",
        "<br>"
      ]
    }
  ]
}